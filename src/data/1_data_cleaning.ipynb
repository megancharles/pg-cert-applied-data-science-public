{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644a6637",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc61345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d15e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    base_dir = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    base_dir = Path().resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb614998",
   "metadata": {},
   "source": [
    "1. Loading & cleaning the data - load a raw CSV file containing product data, remove duplicate entries based on product name and ingredients, and split the 'food_groups_en' column into separate food group and subgroup columns. Then clean and standardise the data, keeping only relevant columns, convert all columns to object type, and ensure the ingredient text is lowercase. Finally, save the cleaned DataFrame to an Excel file for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b68eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "file_path = base_dir / \"data\" / \"raw\" / \"raw_products_17052025.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df.drop_duplicates(subset=['product_name'])\n",
    "df_clean = df_clean.drop_duplicates(subset=['ingredients_text'])\n",
    "\n",
    "# Split 'food_groups_en' into 2 columns\n",
    "food_groups = df_clean[\"food_groups_en\"].str.split(\",\", expand=True)\n",
    "food_groups.columns = [f\"food_group_{i+1}\" for i in range(food_groups.shape[1])]\n",
    "\n",
    "# Add the newly created food group columns back to the original DataFrame\n",
    "df_clean = pd.concat([df_clean, food_groups], axis=1)\n",
    "\n",
    "# Keep only 'food_group_1' as 'food_group' and 'food_group_2' as 'food_subgroup'\n",
    "df_clean['food_group'] = df_clean['food_group_1']\n",
    "df_clean['food_subgroup'] = df_clean['food_group_2']\n",
    "df_clean = df_clean.dropna(subset=['food_group', 'food_subgroup'])\n",
    "\n",
    "# Drop all food group columns except 'food_group' and 'food_subgroup'\n",
    "df_clean = df_clean.drop(columns=['food_group_1', 'food_group_2', 'food_group_3'], errors='ignore')\n",
    "\n",
    "# Convert all columns to 'object' type\n",
    "df_clean = df_clean.astype('object')\n",
    "df_clean['ingredients_text'] = df_clean['ingredients_text'].str.lower()\n",
    "\n",
    "df_clean = df_clean[[\n",
    "    \"food_group\",\n",
    "    \"food_subgroup\",\n",
    "    \"nova_group\",\n",
    "    \"nutriscore_grade\",\n",
    "    \"ecoscore_grade\",\n",
    "    \"ingredients_text\"\n",
    "]]\n",
    "\n",
    "# Output\n",
    "output_path = base_dir / \"data\" / \"processed\" / \"1_cleaned_products.xlsx\"\n",
    "df_clean.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036978d",
   "metadata": {},
   "source": [
    "2. Translating and preparing ingredients -  load a cleaned product dataset, sample 500 rows per ecoscore grade, and prepare the data for ingredient translation using the OpenAI GPT-4 Turbo model. Define a batch processing function that sends ingredient lists to the model for cleaning, standardisation, and translation into English, following specific rules. Save clean results incrementally to a new Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d71f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "file_path = base_dir / \"data\" / \"processed\" / \"1_cleaned_products.xlsx\"\n",
    "df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "\n",
    "# API key has been redacted for security\n",
    "openai.api_key = \"redacted\"\n",
    "\n",
    "df = df.groupby('ecoscore_grade', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), 500), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "output_path = base_dir / \"data\" / \"processed\" / \"2_translated_ingredients.xlsx\"\n",
    "\n",
    "# Ensure the column exists\n",
    "if 'translated_ingredients' not in df.columns:\n",
    "    df['translated_ingredients'] = None\n",
    "\n",
    "def clean_ingredients_with_gpt_batch(df, model=\"gpt-4-turbo\", delay=1.5, batch_size=10):\n",
    "    total_rows = len(df)\n",
    "\n",
    "    for start in tqdm(range(0, total_rows, batch_size), desc=\"Processing batches\"):\n",
    "        end = min(start + batch_size, total_rows)\n",
    "        batch = df.iloc[start:end].copy()\n",
    "        batch_cleaned = []\n",
    "\n",
    "        for i, row in batch.iterrows():\n",
    "            if pd.notnull(row['translated_ingredients']):\n",
    "                batch_cleaned.append(row['translated_ingredients'])\n",
    "                continue\n",
    "\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a food ingredient preprocessing system. Clean and standardize the provided ingredient list using the following rules. \"\n",
    "                        \"Your goal is to output a clean, comma-separated list of English food ingredient names. Follow the steps exactly:\\n\\n\"\n",
    "                        \"1. Remove all numbers and special characters, except for commas and spaces.\\n\"\n",
    "                        \"2. Remove any extra spaces between words.\\n\"\n",
    "                        \"3. Translate all ingredient names into English.\\n\"\n",
    "                        \"4. Normalize synonymous ingredients. For example, use 'rapeseed oil' instead of 'canola oil' or 'rapeseed (canola)'.\\n\"\n",
    "                        \"5. Expand general terms like 'spices' or 'vegetable oil' into their individual ingredients if they are listed.\\n\"\n",
    "                        \"6. Break down compound or blend ingredients into their components. For example, if 'chocolate chips' contains 'sugar, cocoa paste, cocoa butter, emulsifier: soy lecithins, aroma', list those individually.\\n\"\n",
    "                        \"7. Group related ingredients under consistent naming. For example, list 'lecithins' and 'mono- and diglycerides' as 'emulsifiers' but preserve original ingredient words.\\n\"\n",
    "                        \"8. Remove any disclaimers or allergy warnings, such as 'may contain traces of'.\\n\"\n",
    "                        \"9. If the ingredient list is unreadable or not in a valid food format, return exactly this text: untranslated or unreadable\\n\\n\"\n",
    "                        \"Output format:\\n\"\n",
    "                        \"- A single, comma-separated list of clean, lowercase, English ingredient names only.\\n\"\n",
    "                        \"- No explanations, categories, bullet points, symbols, or additional formatting.\\n\"\n",
    "                        \"- The output must be plain text, with one line and no newline characters.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"### Input:\\n{row['ingredients_text']}\\n\\n### Cleaned:\"\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                response = openai.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=0.3,\n",
    "                )\n",
    "                cleaned = response.choices[0].message.content.strip()\n",
    "            except Exception as e:\n",
    "                print(f\"Error on row {start + i}: {e}\")\n",
    "                cleaned = None\n",
    "\n",
    "            batch_cleaned.append(cleaned)\n",
    "            time.sleep(delay)\n",
    "\n",
    "        # Assign cleaned results to the correct slice\n",
    "        df.loc[start:end - 1, 'translated_ingredients'] = batch_cleaned\n",
    "\n",
    "        # Save after each batch\n",
    "        df.iloc[:end].to_excel(output_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Run the processing\n",
    "df = clean_ingredients_with_gpt_batch(df)\n",
    "\n",
    "print(f\"\\nFinished! All cleaned data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad09af92",
   "metadata": {},
   "source": [
    "3. Cleaning ingredient lists - load the translated ingredient dataset, remove rows with null or duplicate translated ingredients, and filter out rows marked as 'untranslated' or 'unreadable'. Define a function to recursively extract root ingredients from nested ingredient lists, apply this function to clean and flatten the ingredient lists, and save the resulting DataFrame with cleaned root ingredients to a new Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "file_path = base_dir / \"data\" / \"processed\" / \"2_translated_ingredients.xlsx\"\n",
    "df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "\n",
    "# Root ingredient extractor function\n",
    "def extract_root_ingredients(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    def extract_recursive(s):\n",
    "        if '(' not in s:\n",
    "            return [x.strip() for x in re.sub(r'\\b\\w+:\\s*', '', s).split(',') if x.strip()]\n",
    "\n",
    "        result = []\n",
    "        while '(' in s:\n",
    "            match = re.search(r'(\\b[^,()]+)?\\s*\\(([^()]+)\\)', s)\n",
    "            if not match:\n",
    "                break\n",
    "\n",
    "            # Extract parent and inner content\n",
    "            inner = match.group(2)   # 'raisins, dried blue grapes...'\n",
    "\n",
    "            # Recursively extract from inside parentheses\n",
    "            extracted = extract_recursive(inner)\n",
    "            result.extend(extracted)\n",
    "\n",
    "            # Remove the whole 'parent (inner)' from the string\n",
    "            s = s[:match.start()] + s[match.end():]\n",
    "\n",
    "        # Now process remaining outer text (without labels)\n",
    "        outer = [x.strip() for x in re.sub(r'\\b\\w+:\\s*', '', s).split(',') if x.strip()]\n",
    "        result.extend(outer)\n",
    "        return result\n",
    "\n",
    "    ingredients = extract_recursive(text)\n",
    "    return ', '.join(ingredients)\n",
    "\n",
    "# Clean and filter\n",
    "df_clean = df.dropna(subset=['translated_ingredients'])\n",
    "df_clean = df_clean.drop_duplicates(subset=['translated_ingredients'])\n",
    "df_clean = df_clean[~df_clean['translated_ingredients'].str.contains('untranslated|unreadable', case=False)].copy()\n",
    "\n",
    "# Add clean ingredient column (will later be removed)\n",
    "df_clean['cleaned_ingredients'] = df_clean['translated_ingredients'].str.strip().str.lower()\n",
    "\n",
    "# Apply root ingredient extraction function & create cleaned root ingredients column\n",
    "df_clean['cleaned_root_ingredients'] = df_clean['cleaned_ingredients'].apply(extract_root_ingredients)\n",
    "df_clean['cleaned_root_ingredients'] = 'ingredients: ' + df_clean['cleaned_root_ingredients']\n",
    "df_clean = df_clean.drop(columns=['cleaned_ingredients'])\n",
    "\n",
    "# Output\n",
    "output_path = base_dir / \"data\" / \"processed\" / \"3_cleaned_ingredients.xlsx\"\n",
    "df_clean.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcc5fa",
   "metadata": {},
   "source": [
    "5. Copy final dataset to 'final' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fbe6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/pg-cert-applied-data-science-public/data/final/1_cleaned_ingredients.xlsx')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_path = base_dir / \"data\" / \"final\" / \"1_cleaned_ingredients.xlsx\"\n",
    "shutil.copy2(output_path, destination_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
